# -*- coding: utf-8 -*-
"""BTL_XLA_KNN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tiOj6li7yt3tZxNeDlKk-73_DNlHInG2
"""

# !pip install opencv-python numpy matplotlib scikit-learn

import cv2
import numpy as np
import matplotlib.pyplot as plt
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from collections import Counter
import os

# 0 0.8665292390625 0.13456756718750001 0.2476783625 0.1236081078125 0.03405555625 0.754216215625 0.6876491234375 0.8606655406250001

# ==================== DỮ LIỆU ĐẦU VÀO VÀ THAM SỐ ====================
# ⚠️ THAY ĐỔI ĐƯỜNG DẪN NÀY SAU KHI UPLOAD ẢNH LÊN COLAB
IMAGE_PATH = 'bien_so_nghieng.jpg'

# Tọa độ 4 góc chuẩn hóa bạn cung cấp: [x1, y1, x2, y2, x3, y3, x4, y4]
# Sẽ được sắp xếp lại thành (TL, TR, BR, BL) trong hàm order_points_corrected
normalized_coords_raw = np.array([
    # Điểm 1: x=0.8665, y=0.1345
    [0.8665292390625, 0.13456756718750001],

    # Điểm 2: x=0.2476, y=0.1236
    [0.2476783625, 0.1236081078125],

    # Điểm 3: x=0.0340, y=0.7542
    [0.03405555625, 0.754216215625],

    # Điểm 4: x=0.6876, y=0.8606
    [0.6876491234375, 0.8606655406250001]
])
# ==================== HÀM TIỆN ÍCH: SẮP XẾP TỌA ĐỘ ====================
def order_points_corrected(pts):
    """
    Sắp xếp 4 điểm tọa độ theo thứ tự chuẩn: Trên-Trái, Trên-Phải, Dưới-Phải, Dưới-Trái (TL, TR, BR, BL).
    """
    pts = np.array(pts, dtype = "float32")
    rect = np.zeros((4, 2), dtype = "float32")

    # Trên-Trái (TL) có tổng nhỏ nhất, Dưới-Phải (BR) có tổng lớn nhất
    s = pts.sum(axis = 1)
    rect[0] = pts[np.argmin(s)]
    rect[2] = pts[np.argmax(s)]

    # Lấy 2 điểm còn lại
    remaining_pts = np.delete(pts, [np.argmin(s), np.argmax(s)], axis=0)

    # Trên-Phải (TR) có hiệu (x-y) nhỏ nhất, Dưới-Trái (BL) có hiệu lớn nhất
    remaining_diff = np.diff(remaining_pts, axis=1).flatten()

    rect[1] = remaining_pts[np.argmin(remaining_diff)] # TR
    rect[3] = remaining_pts[np.argmax(remaining_diff)] # BL

    return rect

# Sắp xếp tọa độ đầu vào
sorted_normalized_points = order_points_corrected(normalized_coords_raw)
print("Tọa độ 4 góc đã sắp xếp (TL, TR, BR, BL):")
print(sorted_normalized_points)
print("-" * 60)

def rectify_license_plate(image_path, norm_points):
    """Làm thẳng biển số xe từ ảnh nghiêng sử dụng tọa độ chuẩn hóa."""
    img = cv2.imread(image_path)
    if img is None:
        print(f"❌ Lỗi: Không thể tải ảnh từ: {image_path}")
        return None, 0, 0

    # 1. Chuyển tọa độ chuẩn hóa sang tọa độ pixel
    H_img, W_img = img.shape[:2]
    pixel_points = norm_points.copy()
    pixel_points[:, 0] *= W_img
    pixel_points[:, 1] *= H_img
    input_pts = np.float32(pixel_points)

    # 2. Định nghĩa kích thước và tọa độ đích
    RECTIFIED_WIDTH = 400
    RECTIFIED_HEIGHT = 400

    output_pts = np.float32([
        [0, 0], [RECTIFIED_WIDTH - 1, 0],
        [RECTIFIED_WIDTH - 1, RECTIFIED_HEIGHT - 1], [0, RECTIFIED_HEIGHT - 1]
    ])

    # 3. Tính và Áp dụng ma trận biến đổi phối cảnh
    M = cv2.getPerspectiveTransform(input_pts, output_pts)
    # Chuyển đổi màu từ BGR sang RGB cho Matplotlib
    img_rectified = cv2.warpPerspective(cv2.cvtColor(img, cv2.COLOR_BGR2RGB), M, (RECTIFIED_WIDTH, RECTIFIED_HEIGHT))

    # Hiển thị ảnh
    plt.figure(figsize=(10, 5))
    plt.subplot(1, 2, 1)
    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
    plt.title("Ảnh gốc")
    plt.axis('off')

    plt.subplot(1, 2, 2)
    plt.imshow(img_rectified)
    plt.title("Biển số đã làm thẳng")
    plt.axis('off')
    plt.show()

    return img_rectified, W_img, H_img

# Thực thi làm thẳng ảnh
img_rectified, W_img, H_img = rectify_license_plate(IMAGE_PATH, sorted_normalized_points)

def segment_characters_debug(img_rectified):
    """
    Phân đoạn ký tự bằng Ngưỡng Otsu và Phép Đóng (Morphological Closing).
    """
    if img_rectified is None:
        print("Lỗi: Không có ảnh đã làm thẳng để xử lý.")
        return []

    print("\n--- DEBUG: BƯỚC TIỀN XỬ LÝ (Otsu + Morphology) ---")
    gray = cv2.cvtColor(img_rectified, cv2.COLOR_RGB2GRAY)

    blurred = cv2.GaussianBlur(gray, (5, 5), 0)

    # 1. ÁP DỤNG NGƯỠNG OTSU (Chương 3.1.5 - Kỹ thuật tìm tách ngưỡng tự động)
    # Tự động tìm ngưỡng tối ưu.
    ret_otsu, binary = cv2.threshold(blurred, 0, 255,
                                    cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
    print(f"Ngưỡng Otsu tự động tìm được: {ret_otsu}")

    plt.figure(figsize=(6, 3))
    plt.imshow(binary, cmap='gray')
    plt.title("Ảnh Nhị Phân (Sau Ngưỡng Otsu)")
    plt.show()

    # 2. ÁP DỤNG PHÉP ĐÓNG (MORPH_CLOSE) (Chương 4.4.1)
    # Phép Đóng = Giãn (Dilate) rồi Co (Erode).
    # Mục đích: Nối liền các ký tự bị đứt gãy (do ngưỡng Otsu hoặc ảnh mờ).
    kernel = np.ones((3,3), np.uint8)
    binary_morphed = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel, iterations=1) # 2 lần lặp

    plt.figure(figsize=(6, 3))
    plt.imshow(binary_morphed, cmap='gray')
    plt.title("Ảnh sau Phép Đóng (Nối liền ký tự)")
    plt.show()

    # --- BƯỚC B: TÌM & LỌC CONTOURS (trên ảnh đã Đóng) ---
    print("\n--- DEBUG: TÌM VÀ LỌC CONTOURS ---")
    contours, _ = cv2.findContours(binary_morphed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    # Tham số lọc (Điều chỉnh cho ảnh 400x200)
    MIN_W = 10      # Chiều rộng tối thiểu
    MAX_H = 180     # Chiều cao max (gần bằng chiều cao ảnh)
    MIN_H = 50      # Chiều cao min (loại bỏ dấu chấm/nhiễu)
    MIN_ASPECT = 0.1
    MAX_ASPECT = 0.9  # Nới lỏng cho ký tự 'V', 'M'

    char_contours = []
    debug_img_bgr = cv2.cvtColor(img_rectified.copy(), cv2.COLOR_RGB2BGR)

    for i, cnt in enumerate(contours):
        x, y, w, h = cv2.boundingRect(cnt)
        aspect_ratio = w / h

        condition_w = w > MIN_W
        condition_h = h > MIN_H and h < MAX_H
        condition_aspect = aspect_ratio > MIN_ASPECT and aspect_ratio < MAX_ASPECT

        if h > 20: # Chỉ in log cho contour đáng kể
            print(f"Contour {i}: x={x}, y={y}, w={w}, h={h}, tỷ lệ (w/h)={aspect_ratio:.2f}")
            print(f"   -> Lọc W={condition_w}, Lọc H={condition_h}, Lọc Tỷ lệ={condition_aspect}")

        if condition_w and condition_h and condition_aspect:
             char_contours.append((x, y, w, h))
             cv2.rectangle(debug_img_bgr, (x, y), (x + w, y + h), (0, 255, 0), 2)
        else:
             cv2.rectangle(debug_img_bgr, (x, y), (x + w, y + h), (0, 0, 255), 1)

    # Sắp xếp theo Vị trí (x)
    char_contours = sorted(char_contours, key=lambda b: b[0])

    plt.figure(figsize=(10, 4))
    plt.imshow(cv2.cvtColor(debug_img_bgr, cv2.COLOR_BGR2RGB))
    plt.title(f"Contours được chấp nhận ({len(char_contours)} ký tự)")
    plt.show()

    # --- BƯỚC C: TRÍCH XUẤT KÝ TỰ (từ ảnh nhị phân GỐC) ---
    char_images = []
    if len(char_contours) > 0:
        print(f"\n✅ Đã trích xuất {len(char_contours)} vùng ký tự sau khi lọc.")
        plt.figure(figsize=(15, 3))
        for i, (x, y, w, h) in enumerate(char_contours):
            padding = 2
            # Cắt từ ảnh nhị phân GỐC (binary)
            char_img = binary[max(0, y-padding):min(binary_morphed.shape[0], y+h+padding),
                              max(0, x-padding):min(binary_morphed.shape[1], x+w+padding)]

            char_images.append(char_img)

            plt.subplot(1, len(char_contours), i+1)
            plt.imshow(char_img, cmap='gray')
            plt.title(f"Ký tự {i+1}")
            plt.axis('off')
        plt.show()
    else:
        print("\n❌ Kết quả cuối cùng: Không trích xuất được ký tự nào hợp lệ.")

    return char_images

# Thực thi phân đoạn ký tự
char_images = segment_characters_debug(img_rectified)

MIN_CONTOUR_AREA = 40


RESIZED_IMAGE_WIDTH = 20
RESIZED_IMAGE_HEIGHT = 30

def genData():
    imgTrainingNumbers = cv2.imread("training_chars.png")            # read in training numbers image
    #imgTrainingNumbers = cv2.resize(imgTrainingNumbers, dsize = None, fx = 0.5, fy = 0.5)

    # Add a check to see if the image was loaded successfully
    if imgTrainingNumbers is None:
        print("Error: Could not load training_chars.png. Make sure the file exists in the correct directory.")
        return

    imgGray = cv2.cvtColor(imgTrainingNumbers, cv2.COLOR_BGR2GRAY)          # get grayscale image
    imgBlurred = cv2.GaussianBlur(imgGray, (5,5), 0)                        # blur

                                                        # filter image from grayscale to black and white
    imgThresh = cv2.adaptiveThreshold(imgBlurred,                           # input image
                                      255,                                  # make pixels that pass the threshold full white
                                      cv2.ADAPTIVE_THRESH_GAUSSIAN_C,       # use gaussian rather than mean, seems to give better results
                                      cv2.THRESH_BINARY_INV,                # invert so foreground will be white, background will be black
                                      11,                                   # size of a pixel neighborhood used to calculate threshold value
                                      2)                                    # constant subtracted from the mean or weighted mean

    from google.colab.patches import cv2_imshow
    cv2_imshow(imgThresh)      # show threshold image for reference

    imgThreshCopy = imgThresh.copy()        # make a copy of the thresh image, this in necessary b/c findContours modifies the image

    npaContours, hierarchy = cv2.findContours(imgThreshCopy,        # input image, make sure to use a copy since the function will modify this image in the course of finding contours
                                                 cv2.RETR_EXTERNAL,                 # retrieve the outermost contours only
                                                 cv2.CHAIN_APPROX_SIMPLE)           # compress horizontal, vertical, and diagonal segments and leave only their end points

                                # declare empty numpy array, we will use this to write to file later
                                # zero rows, enough cols to hold all image data
    npaFlattenedImages =  np.empty((0, RESIZED_IMAGE_WIDTH * RESIZED_IMAGE_HEIGHT))


    intClassifications = []         # declare empty classifications list, this will be our list of how we are classifying our chars from user input, we will write to file at the end

                                    # possible chars we are interested in are digits 0 through 9, put these in list intValidChars
    intValidChars = [ord('0'), ord('1'), ord('2'), ord('3'), ord('4'), ord('5'), ord('6'), ord('7'), ord('8'), ord('9'),
                     ord('A'), ord('B'), ord('C'), ord('D'), ord('E'), ord('F'), ord('G'), ord('H'), ord('I'), ord('J'),
                     ord('K'), ord('L'), ord('M'), ord('N'), ord('O'), ord('P'), ord('Q'), ord('R'), ord('S'), ord('T'),
                     ord('U'), ord('V'), ord('W'), ord('X'), ord('Y'), ord('Z')] #Là mã ascii của mấy chữ này

    for npaContour in npaContours:                          # for each contour
        if cv2.contourArea(npaContour) > MIN_CONTOUR_AREA:          # if contour is big enough to consider
            [intX, intY, intW, intH] = cv2.boundingRect(npaContour)         # get and break out bounding rect

                                                # draw rectangle around each contour as we ask user for input
            cv2.rectangle(imgTrainingNumbers,           # draw rectangle on original training image
                          (intX, intY),                 # upper left corner
                          (intX+intW,intY+intH),        # lower right corner
                          (0, 0, 255),                  # red
                          2)                            # thickness

            imgROI = imgThresh[intY:intY+intH, intX:intX+intW]                                  # crop char out of threshold image
            imgROIResized = cv2.resize(imgROI, (RESIZED_IMAGE_WIDTH, RESIZED_IMAGE_HEIGHT))     # resize image, this will be more consistent for recognition and storage

            cv2_imshow(imgROI)                    # show cropped out char for reference
            cv2_imshow(imgROIResized)      # show resized image for reference

            cv2_imshow(imgTrainingNumbers)      # show training numbers image, this will now have red rectangles drawn on it

            intChar = cv2.waitKey(0)                     # get key press

            if intChar == 27:                   # if esc key was pressed
                sys.exit()                      # exit program
            elif intChar in intValidChars:      # else if the char is in the list of chars we are looking for . . .

                intClassifications.append(intChar)        # append classification char to integer list of chars (we will convert to float later before writing to file)
                #Là file chứa label của tất cả các ảnh mẫu, tổng cộng có 32 x 5 = 160 mẫu.
                npaFlattenedImage = imgROIResized.reshape((1, RESIZED_IMAGE_WIDTH * RESIZED_IMAGE_HEIGHT))  # flatten image to 1d numpy array so we can write to file later

                npaFlattenedImages = np.append(npaFlattenedImages, npaFlattenedImage, 0)                    # add current flattened impage numpy array to list of flattened image numpy arrays

            # end if
        # end if
    # end for

    fltClassifications = np.array(intClassifications, np.float32)                   # convert classifications list of ints to numpy array of floats

    npaClassifications = fltClassifications.reshape((fltClassifications.size, 1))   # flatten numpy array of floats to 1d so we can write to file later

    print ("\n\ntraining complete !!\n")

    np.savetxt("classifications.txt", npaClassifications)           # write flattened images to file
    np.savetxt("flattened_images.txt", npaFlattenedImages)          #

    cv2.destroyAllWindows()             # remove windows from memory

    return


genData()

